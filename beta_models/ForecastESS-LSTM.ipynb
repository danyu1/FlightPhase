{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941a1163",
   "metadata": {},
   "source": [
    "# Pre Process and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7dbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse, os, re, json, random, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ------------------ config ------------------\n",
    "SEQLEN = 32\n",
    "EPOCHS = 30\n",
    "BATCH = 128\n",
    "LR = 1e-3\n",
    "HID = 64\n",
    "MIN_TRAIN_SAMPLES = 60   # skip tiny tasks\n",
    "OUT_DIR_DEFAULT = \"models_ESS_LSTM\"\n",
    "NPY_PATH_DEFAULT = r\"C:\\Users\\danie\\OneDrive\\Desktop\\FlightPhase\\FlightPhase\\scripts\\tfrrs_performances.npy\"\n",
    "SEED = 42\n",
    "\n",
    "# ------------------ utils -------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "RUN_EVENTS = {\n",
    "    \"60 Meters\",\"100 Meters\",\"200 Meters\",\"400 Meters\",\"800 Meters\",\"1500 Meters\",\n",
    "    \"Mile\",\"3000 Meters\",\"5000 Meters\",\"10000 Meters\",\"60 Hurdles\",\"110 Hurdles\",\n",
    "    \"400 Hurdles\",\"3000 Steeplechase\",\"DMR\",\"4 x 100 Relay\",\"4 x 400 Relay\"\n",
    "}\n",
    "FIELD_EVENTS = {\n",
    "    \"Long Jump\",\"Triple Jump\",\"High Jump\",\"Pole Vault\",\n",
    "    \"Shot Put\",\"Discus\",\"Hammer\",\"Javelin\",\"Weight Throw\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb54840",
   "metadata": {},
   "source": [
    "# Define Clean Up Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafee08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical_event(e: str) -> str:\n",
    "    if e in RUN_EVENTS or e in FIELD_EVENTS: return e\n",
    "    el = (e or \"\").strip().lower()\n",
    "    alias = {\n",
    "        \"60m\":\"60 Meters\",\"100m\":\"100 Meters\",\"200m\":\"200 Meters\",\"400m\":\"400 Meters\",\n",
    "        \"800m\":\"800 Meters\",\"1500m\":\"1500 Meters\",\"mile\":\"Mile\",\n",
    "        \"3k\":\"3000 Meters\",\"5k\":\"5000 Meters\",\"10k\":\"10000 Meters\",\n",
    "    }\n",
    "    return alias.get(el, e)\n",
    "\n",
    "def parse_time_to_seconds(s: str) -> float | None:\n",
    "    if not s: return None\n",
    "    sl = s.strip().lower()\n",
    "    if sl in {\"dnf\",\"dq\",\"fs\",\"nt\",\"ns\"}: return None\n",
    "    s = s.replace(\" \", \"\")\n",
    "    if \":\" in s:\n",
    "        parts = s.split(\":\")\n",
    "        try:\n",
    "            if len(parts)==2: m,sec = int(parts[0]), float(parts[1]); return m*60+sec\n",
    "            if len(parts)==3: h,m,sec = int(parts[0]),int(parts[1]),float(parts[2]); return h*3600+m*60+sec\n",
    "        except: return None\n",
    "    try: return float(s)\n",
    "    except: return None\n",
    "\n",
    "def parse_distance_to_meters(s: str) -> float | None:\n",
    "    if not s: return None\n",
    "    sl = s.strip().lower()\n",
    "    if sl in {\"nm\"}: return None\n",
    "    if re.match(r\"^\\d{1,3}-\\d{1,2}(\\.\\d+)?$\", sl):  # ft-in\n",
    "        ft, inch = sl.split(\"-\")\n",
    "        try:\n",
    "            total_inches = int(ft)*12 + float(inch)\n",
    "            return total_inches * 0.0254\n",
    "        except: return None\n",
    "    if sl.endswith(\"m\"): sl = sl[:-1]\n",
    "    try: return float(sl)\n",
    "    except: return None\n",
    "\n",
    "def mark_to_numeric(event: str, mark: str) -> tuple[float|None, bool]:\n",
    "    if event in RUN_EVENTS:   return parse_time_to_seconds(mark), True\n",
    "    if event in FIELD_EVENTS: return parse_distance_to_meters(mark), False\n",
    "    t = parse_time_to_seconds(mark)\n",
    "    if t is not None and (\":\" in (mark or \"\") or t < 30): return t, True\n",
    "    d = parse_distance_to_meters(mark)\n",
    "    return ((d, False) if d is not None else (None, True))\n",
    "\n",
    "def load_df(npy_path: str) -> pd.DataFrame:\n",
    "    arr = np.load(npy_path, allow_pickle=False)\n",
    "    df = pd.DataFrame.from_records(arr)\n",
    "    keep = [\"Division\",\"School\",\"Gender\",\"SeasonLabel\",\"SeasonYear\",\"Event\",\n",
    "            \"Athlete\",\"MarkOrTime\",\"Wind\",\"Meet\",\"MeetDate\"]\n",
    "    df = df[keep].copy()\n",
    "    for c in keep: df[c] = df[c].astype(\"string\").str.strip()\n",
    "    df[\"Event\"] = df[\"Event\"].map(canonical_event)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"MeetDate\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"date\",\"Event\",\"Athlete\",\"SeasonLabel\",\"SeasonYear\"])\n",
    "    val_is_time = df.apply(lambda r: mark_to_numeric(r[\"Event\"], r[\"MarkOrTime\"]), axis=1, result_type=\"expand\")\n",
    "    df[\"value\"] = val_is_time[0]; df[\"is_time\"] = val_is_time[1]\n",
    "    df = df.dropna(subset=[\"value\"])\n",
    "    df[\"key\"] = df[\"Athlete\"].str.lower().str.strip() + \"||\" + df[\"Event\"].str.lower().str.strip() + \"||\" + df[\"Gender\"]\n",
    "    df[\"season_key\"] = df[\"SeasonYear\"].astype(\"Int64\").astype(\"string\") + \"-\" + df[\"SeasonLabel\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f735c9b",
   "metadata": {},
   "source": [
    "# Next Season Peak Per Athelte + Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_peak(g: pd.DataFrame) -> float:\n",
    "    return g[\"value\"].min() if g[\"is_time\"].iloc[0] else g[\"value\"].max()\n",
    "\n",
    "def build_targets(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    peaks = (df.groupby([\"key\",\"season_key\"], as_index=False)\n",
    "               .apply(agg_peak).rename(columns={None:\"peak_value\"}))\n",
    "    meta = (df.groupby([\"key\",\"season_key\"], as_index=False)\n",
    "              .agg(SeasonYear=(\"SeasonYear\",\"first\"),\n",
    "                   SeasonLabel=(\"SeasonLabel\",\"first\"),\n",
    "                   Event=(\"Event\",\"first\"),\n",
    "                   Gender=(\"Gender\",\"first\"),\n",
    "                   is_time=(\"is_time\",\"first\")))\n",
    "    peaks = peaks.merge(meta, on=[\"key\",\"season_key\"], how=\"left\")\n",
    "    def next_season(label, year): return f\"{int(year+1)}-{label}\"\n",
    "    peaks[\"next_season_key\"] = peaks.apply(lambda r: next_season(r[\"SeasonLabel\"], int(r[\"SeasonYear\"])), axis=1)\n",
    "    out = peaks.merge(peaks[[\"key\",\"season_key\",\"peak_value\"]]\n",
    "                      .rename(columns={\"season_key\":\"next_season_key\",\"peak_value\":\"y_next\"}),\n",
    "                      on=[\"key\",\"next_season_key\"], how=\"left\").drop(columns=[\"next_season_key\"])\n",
    "    out = out.dropna(subset=[\"y_next\"]).reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa80dfb",
   "metadata": {},
   "source": [
    "# Build SequencesFrom Raw Marks Up to the End of the Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(df: pd.DataFrame, seqlen=SEQLEN):\n",
    "    df = df.sort_values([\"key\",\"date\"]).reset_index(drop=True)\n",
    "    def make_seq(g):\n",
    "        vals = g[\"value\"].to_numpy()\n",
    "        days = g[\"date\"].diff().dt.days.fillna(0).clip(lower=0).to_numpy()\n",
    "        wind = pd.to_numeric(g[\"Wind\"].str.replace(\"+\",\"\", regex=False).str.replace(\"m/s\",\"\", regex=False),\n",
    "                             errors=\"coerce\").fillna(0.0).to_numpy()\n",
    "        X = np.stack([vals, days, wind], axis=1).astype(\"float32\")\n",
    "        return X[-seqlen:] if len(X)>seqlen else X\n",
    "    seqs = {}\n",
    "    for (k,s), g in df.groupby([\"key\",\"season_key\"]): seqs[(k,s)] = make_seq(g)\n",
    "    return seqs\n",
    "\n",
    "def pad_seq(X, L=SEQLEN):\n",
    "    if len(X)>=L: return X\n",
    "    pad = np.zeros((L-len(X), X.shape[1]), dtype=\"float32\")\n",
    "    return np.vstack([pad, X])\n",
    "\n",
    "class SeqDS(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780c048",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMReg(nn.Module):\n",
    "    def __init__(self, in_dim=3, hid=64, layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(in_dim, hid, num_layers=layers, batch_first=True,\n",
    "                            dropout=(dropout if layers>1 else 0.0))\n",
    "        self.head = nn.Sequential(nn.LayerNorm(hid), nn.Linear(hid, 1))\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.head(last).squeeze(-1)\n",
    "\n",
    "def safe_slug(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"_\", s).strip(\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480acc6e",
   "metadata": {},
   "source": [
    "# Training All Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dab0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    set_seed(SEED)\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-i\",\"--input\", default=NPY_PATH_DEFAULT)\n",
    "    ap.add_argument(\"-o\",\"--outdir\", default=OUT_DIR_DEFAULT)\n",
    "    ap.add_argument(\"--min-train\", type=int, default=MIN_TRAIN_SAMPLES)\n",
    "    ap.add_argument(\"--epochs\", type=int, default=EPOCHS)\n",
    "    ap.add_argument(\"--hid\", type=int, default=HID)\n",
    "    ap.add_argument(\"--seqlen\", type=int, default=SEQLEN)\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    os.makedirs(args.outdir, exist_ok=True)\n",
    "    df = load_df(args.input)\n",
    "    targets_all = build_targets(df)\n",
    "    seqs_all = build_sequences(df, args.seqlen)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    metrics = []\n",
    "    tasks = (targets_all[[\"Event\",\"Gender\",\"SeasonLabel\"]]\n",
    "             .drop_duplicates().sort_values([\"Gender\",\"SeasonLabel\",\"Event\"]))\n",
    "    for _, t in tasks.iterrows():\n",
    "        event, gender, season = t[\"Event\"], t[\"Gender\"], t[\"SeasonLabel\"]\n",
    "        tmask = ((targets_all[\"Event\"]==event) &\n",
    "                 (targets_all[\"Gender\"]==gender) &\n",
    "                 (targets_all[\"SeasonLabel\"]==season))\n",
    "        T = targets_all[tmask].copy()\n",
    "        if T.empty: continue\n",
    "\n",
    "        X_list, y_list, years = [], [], []\n",
    "        for _, r in T.iterrows():\n",
    "            X = seqs_all.get((r[\"key\"], r[\"season_key\"]))\n",
    "            if X is None: continue\n",
    "            X_list.append(pad_seq(X, args.seqlen))\n",
    "            y_list.append(float(r[\"y_next\"]))\n",
    "            years.append(int(r[\"SeasonYear\"]))\n",
    "        if not X_list: continue\n",
    "\n",
    "        X = np.stack(X_list); y = np.array(y_list, dtype=\"float32\"); years = np.array(years)\n",
    "        train_m = years <= 2023; val_m = years == 2024; test_m = years >= 2025\n",
    "        if train_m.sum() < args.min_train:\n",
    "            # try a random split fallback if time-based too small\n",
    "            idx = np.arange(len(X)); np.random.shuffle(idx)\n",
    "            n = len(idx); a=max(args.min_train, int(0.7*n)); b=int(0.85*n)\n",
    "            if a>=n: continue\n",
    "            train_m = np.zeros(n,bool); val_m=np.zeros(n,bool); test_m=np.zeros(n,bool)\n",
    "            train_m[idx[:a]]=True; val_m[idx[a:b]]=True; test_m[idx[b:]]=True\n",
    "\n",
    "        ds_tr, ds_va, ds_te = SeqDS(X[train_m], y[train_m]), SeqDS(X[val_m], y[val_m]), SeqDS(X[test_m], y[test_m])\n",
    "        if len(ds_tr) < args.min_train: \n",
    "            print(f\"Skipping {event} | {gender} | {season} (train {len(ds_tr)} < {args.min_train})\")\n",
    "            continue\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_size=BATCH, shuffle=True)\n",
    "        dl_va = DataLoader(ds_va, batch_size=256)\n",
    "        dl_te = DataLoader(ds_te, batch_size=256)\n",
    "\n",
    "        model = LSTMReg(in_dim=X.shape[-1], hid=args.hid).to(device)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "        loss_fn = nn.L1Loss()\n",
    "\n",
    "        best = 1e9; patience = 0; best_state=None\n",
    "        for ep in range(args.epochs):\n",
    "            # train\n",
    "            model.train(); tot=0; n=0\n",
    "            for xb, yb in dl_tr:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                pred = model(xb); loss = loss_fn(pred, yb)\n",
    "                opt.zero_grad(); loss.backward(); opt.step()\n",
    "                tot += loss.item()*len(xb); n+=len(xb)\n",
    "            tr = tot/max(n,1)\n",
    "            # val\n",
    "            model.eval(); tot=0; n=0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in dl_va:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    pred = model(xb); loss = loss_fn(pred, yb)\n",
    "                    tot += loss.item()*len(xb); n+=len(xb)\n",
    "            va = tot/max(n,1)\n",
    "            print(f\"[ESS-LSTM] {gender} | {season} | {event}  ep {ep:02d}  train={tr:.3f}  val={va:.3f}\")\n",
    "            if va < best - 1e-3:\n",
    "                best, patience = va, 0\n",
    "                best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience += 1\n",
    "            if patience >= 5: break\n",
    "        if best_state is not None: model.load_state_dict(best_state)\n",
    "\n",
    "        # test\n",
    "        model.eval(); tot=0; n=0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_te:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                pred = model(xb); loss = loss_fn(pred, yb)\n",
    "                tot += loss.item()*len(xb); n+=len(xb)\n",
    "        te = tot/max(n,1) if n else float(\"nan\")\n",
    "\n",
    "        # save weights + metadata\n",
    "        subdir = os.path.join(args.outdir, f\"{safe_slug(gender)}__{safe_slug(season)}__{safe_slug(event)}\")\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "        weight_path = os.path.join(subdir, \"model.pth\")\n",
    "        torch.save(model.state_dict(), weight_path)\n",
    "        meta = {\n",
    "            \"model_name\":\"ESS-LSTM\",\n",
    "            \"event\":event,\"gender\":gender,\"season\":season,\n",
    "            \"seqlen\":args.seqlen,\"hid\":args.hid,\"in_dim\":X.shape[-1],\n",
    "            \"train_n\":int(len(ds_tr)),\"val_n\":int(len(ds_va)),\"test_n\":int(len(ds_te)),\n",
    "            \"val_mae\":float(best),\"test_mae\":float(te),\n",
    "            \"created\":datetime.utcnow().isoformat()+\"Z\"\n",
    "        }\n",
    "        with open(os.path.join(subdir,\"meta.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(meta,f,indent=2)\n",
    "        metrics.append(meta)\n",
    "\n",
    "    # write summary CSV\n",
    "    if metrics:\n",
    "        pd.DataFrame(metrics).to_csv(os.path.join(args.outdir,\"summary_metrics.csv\"), index=False)\n",
    "        print(f\"✅ Saved {len(metrics)} ESS-LSTM models → {args.outdir}\")\n",
    "    else:\n",
    "        print(\"⚠️ No tasks trained (insufficient data with current thresholds).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
